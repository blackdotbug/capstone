{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_URL = config.postgresURI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>sexist</th>\n",
       "      <th>of_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>MENTION3394 MENTION2031 MENTION3544 curious as...</td>\n",
       "      <td>0.087480</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>callme</td>\n",
       "      <td>females should not commentate on sport</td>\n",
       "      <td>0.286217</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>\"We're serving leftovers for breakfast\"  #mkr</td>\n",
       "      <td>0.122916</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hostile</td>\n",
       "      <td>MENTION4416 I like a multimedia approach.</td>\n",
       "      <td>0.077411</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>.MENTION3582 MENTION4612 05 SB. Getting Ike in...</td>\n",
       "      <td>0.042951</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>other</td>\n",
       "      <td>Would you really be surprised? #gamergate #SVU...</td>\n",
       "      <td>0.070119</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>benevolent</td>\n",
       "      <td>You've got a strong grip for a kid. https://t....</td>\n",
       "      <td>0.264434</td>\n",
       "      <td>False</td>\n",
       "      <td>10477</td>\n",
       "      <td>9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>other</td>\n",
       "      <td>MENTION3574 MENTION2415 i'm married with kids....</td>\n",
       "      <td>0.286828</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>other</td>\n",
       "      <td>Anyone eliminated yet?  #mkr</td>\n",
       "      <td>0.353405</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>benevolent</td>\n",
       "      <td>Should a intern act like a CEO in business? #W...</td>\n",
       "      <td>0.295632</td>\n",
       "      <td>False</td>\n",
       "      <td>12012</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset                                               text  toxicity  \\\n",
       "0          other  MENTION3394 MENTION2031 MENTION3544 curious as...  0.087480   \n",
       "1         callme             females should not commentate on sport  0.286217   \n",
       "2          other      \"We're serving leftovers for breakfast\"  #mkr  0.122916   \n",
       "3        hostile          MENTION4416 I like a multimedia approach.  0.077411   \n",
       "4          other  .MENTION3582 MENTION4612 05 SB. Getting Ike in...  0.042951   \n",
       "...          ...                                                ...       ...   \n",
       "9995       other  Would you really be surprised? #gamergate #SVU...  0.070119   \n",
       "9996  benevolent  You've got a strong grip for a kid. https://t....  0.264434   \n",
       "9997       other  MENTION3574 MENTION2415 i'm married with kids....  0.286828   \n",
       "9998       other                       Anyone eliminated yet?  #mkr  0.353405   \n",
       "9999  benevolent  Should a intern act like a CEO in business? #W...  0.295632   \n",
       "\n",
       "      sexist  of_id     id  \n",
       "0      False     -1      1  \n",
       "1       True     -1      2  \n",
       "2      False     -1      3  \n",
       "3      False     -1      4  \n",
       "4      False     -1      5  \n",
       "...      ...    ...    ...  \n",
       "9995   False     -1   9996  \n",
       "9996   False  10477   9997  \n",
       "9997   False     -1   9998  \n",
       "9998   False     -1   9999  \n",
       "9999   False  12012  10000  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexism_df = pd.read_sql('SELECT * FROM sexism_data', engine)\n",
    "sexism_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexism_data = sexism_df[['text', 'sexist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "url_pattern = re.compile('''((https?:\\/\\/)?(?:www\\.|(?!www))[a-zA-Z0-9]([a-zA-Z0-9-]+[a-zA-Z0-9])?\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})''', \n",
    "                         flags=re.UNICODE)\n",
    "mention_pattern = re.compile('([^a-zA-Z0-9]|^)@\\S+', flags=re.UNICODE)\n",
    "mention_pattern2 = re.compile('([^0-9]|^)MENTION\\S+', flags=re.UNICODE)\n",
    "hashtag_pattern = re.compile('([^a-zA-Z0-9]|^)#\\S+', flags=re.UNICODE)\n",
    "rt_pattern = re.compile('([^a-zA-Z0-9]|^)(rt|ht|cc|RT)([^a-zA-Z0-9]|$)', flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detweet(text):\n",
    "    return re.sub(url_pattern, '', \n",
    "               re.sub(rt_pattern, '', \n",
    "                      re.sub(mention_pattern2, '',\n",
    "                         re.sub(mention_pattern, '',\n",
    "                             re.sub(hashtag_pattern, '', \n",
    "                                 re.sub(emoji_pattern, '', \n",
    "                                    text))))))\n",
    "def normalize(text):\n",
    "    return re.sub(r\"\\s+\", \" \", #remove extra spaces\n",
    "                  re.sub(r'[^a-zA-Z0-9]', ' ', #remove non alphanumeric, incl punctuation\n",
    "                         text)).lower().strip() #lowercase and strip\n",
    "def fix_encoding_and_unescape(text):\n",
    "    return BeautifulSoup(text.decode('unicode-escape')).get_text()\n",
    "def preprocess(text, fix_encoding=False):\n",
    "    if (type(text)==str) or (type(text)==unicode):\n",
    "        if fix_encoding:\n",
    "            return normalize(detweet(fix_encoding_and_unescape(text)))\n",
    "        else:\n",
    "            return normalize(detweet(text))\n",
    "    else:\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/capstone-tf/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/envs/capstone-tf/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>sexist</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>sexist_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MENTION3394 MENTION2031 MENTION3544 curious as...</td>\n",
       "      <td>0.087480</td>\n",
       "      <td>False</td>\n",
       "      <td>curious as to if the ap style guide has anythi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>females should not commentate on sport</td>\n",
       "      <td>0.286217</td>\n",
       "      <td>True</td>\n",
       "      <td>females should not commentate on sport</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"We're serving leftovers for breakfast\"  #mkr</td>\n",
       "      <td>0.122916</td>\n",
       "      <td>False</td>\n",
       "      <td>we re serving leftovers for breakfast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MENTION4416 I like a multimedia approach.</td>\n",
       "      <td>0.077411</td>\n",
       "      <td>False</td>\n",
       "      <td>i like a multimedia approach</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.MENTION3582 MENTION4612 05 SB. Getting Ike in...</td>\n",
       "      <td>0.042951</td>\n",
       "      <td>False</td>\n",
       "      <td>05 sb getting ike in 4th parker undrafted a no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Would you really be surprised? #gamergate #SVU...</td>\n",
       "      <td>0.070119</td>\n",
       "      <td>False</td>\n",
       "      <td>would you really be surprised</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>You've got a strong grip for a kid. https://t....</td>\n",
       "      <td>0.264434</td>\n",
       "      <td>False</td>\n",
       "      <td>you ve got a strong grip for a kid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>MENTION3574 MENTION2415 i'm married with kids....</td>\n",
       "      <td>0.286828</td>\n",
       "      <td>False</td>\n",
       "      <td>i m married with kids also 33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Anyone eliminated yet?  #mkr</td>\n",
       "      <td>0.353405</td>\n",
       "      <td>False</td>\n",
       "      <td>anyone eliminated yet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Should a intern act like a CEO in business? #W...</td>\n",
       "      <td>0.295632</td>\n",
       "      <td>False</td>\n",
       "      <td>should a intern act like a ceo in business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  toxicity  sexist  \\\n",
       "0     MENTION3394 MENTION2031 MENTION3544 curious as...  0.087480   False   \n",
       "1                females should not commentate on sport  0.286217    True   \n",
       "2         \"We're serving leftovers for breakfast\"  #mkr  0.122916   False   \n",
       "3             MENTION4416 I like a multimedia approach.  0.077411   False   \n",
       "4     .MENTION3582 MENTION4612 05 SB. Getting Ike in...  0.042951   False   \n",
       "...                                                 ...       ...     ...   \n",
       "9995  Would you really be surprised? #gamergate #SVU...  0.070119   False   \n",
       "9996  You've got a strong grip for a kid. https://t....  0.264434   False   \n",
       "9997  MENTION3574 MENTION2415 i'm married with kids....  0.286828   False   \n",
       "9998                       Anyone eliminated yet?  #mkr  0.353405   False   \n",
       "9999  Should a intern act like a CEO in business? #W...  0.295632   False   \n",
       "\n",
       "                                      text_preprocessed  sexist_target  \n",
       "0     curious as to if the ap style guide has anythi...              0  \n",
       "1                females should not commentate on sport              1  \n",
       "2                 we re serving leftovers for breakfast              0  \n",
       "3                          i like a multimedia approach              0  \n",
       "4     05 sb getting ike in 4th parker undrafted a no...              0  \n",
       "...                                                 ...            ...  \n",
       "9995                      would you really be surprised              0  \n",
       "9996                 you ve got a strong grip for a kid              0  \n",
       "9997                      i m married with kids also 33              0  \n",
       "9998                              anyone eliminated yet              0  \n",
       "9999         should a intern act like a ceo in business              0  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexism_data['text_preprocessed'] = sexism_data['text'].apply(preprocess)\n",
    "sexism_data['sexist_target'] = sexism_data['sexist'].astype(int)\n",
    "sexism_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 13:13:26.029043: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "adapt_data = tf.constant(sexism_data['text_preprocessed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = keras.layers.TextVectorization(output_mode=\"tf-idf\", ngrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(adapt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(sexism_data[['text_preprocessed', 'sexist_target']])\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((train['text_preprocessed'].values, train['sexist_target'].values))\n",
    "test = tf.data.Dataset.from_tensor_slices((test['text_preprocessed'].values, test['sexist_target'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train.batch(2).map(lambda x, y: (text_vectorizer(x), y))\n",
    "test_dataset = test.batch(2).map(lambda x, y: (text_vectorizer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 6s 2ms/step - loss: 0.1356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f858b1d7a50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "model.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "\n",
    "# A integer input for vocab indices.\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = keras.layers.Embedding(text_vectorizer.vocabulary_size(), embedding_dim)(inputs)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = keras.layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "predictions = keras.layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3750/3750 [==============================] - 1460s 389ms/step - loss: 0.4199 - accuracy: 0.8648\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 1460s 389ms/step - loss: 0.4072 - accuracy: 0.8648\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 1431s 382ms/step - loss: 0.4051 - accuracy: 0.8648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f858bb2efd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "# Fit the model using the train and test datasets.\n",
    "model.fit(train_dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 80s 64ms/step - loss: 0.3837 - accuracy: 0.8716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38373079895973206, 0.8715999722480774]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets = [\n",
    "    \"waaaaah the working class’s income is keeping pace with or outstripping inflation but my capital gains aren’t boo fucking hooooo\",\n",
    "    \"I got a haircut today! Woman getting haircut I will now accept (polite, non-sexual) compliments, as is traditional at such times Smiling face\",\n",
    "    \"Am I nervous about Baz bringing someone home for Thanksgiving after we’ve been living by pandemic standards for ~2 years? I just bought a shower curtain and matching towels and bathmats. So evidently, yes.\"\n",
    "]\n",
    "new_data = pd.DataFrame({'text':new_tweets})\n",
    "new_data['text_preprocessed'] = new_data['text'].apply(preprocess)\n",
    "new_dataset = tf.data.Dataset.from_tensor_slices((new_data['text_preprocessed'].values))\n",
    "new_dataset = new_dataset.batch(2).map(lambda x: (text_vectorizer(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17639154],\n",
       "       [0.13177627],\n",
       "       [0.14955333]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vectorizedNN.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
