{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd00329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2da9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_URL = config.postgresURI\n",
    "engine = create_engine(DATABASE_URL)\n",
    "sexism_df = pd.read_sql('SELECT * FROM sexism_data', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ea7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "url_pattern = re.compile('''((https?:\\/\\/)?(?:www\\.|(?!www))[a-zA-Z0-9]([a-zA-Z0-9-]+[a-zA-Z0-9])?\\.[^\\s]{2,}\n",
    "|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|\n",
    "www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})''', flags=re.UNICODE)\n",
    "mention_pattern = re.compile('([^a-zA-Z0-9]|^)@\\S+', flags=re.UNICODE)\n",
    "mention_pattern2 = re.compile('([^0-9]|^)MENTION\\S+', flags=re.UNICODE)\n",
    "hashtag_pattern = re.compile('([^a-zA-Z0-9]|^)#\\S+', flags=re.UNICODE)\n",
    "rt_pattern = re.compile('([^a-zA-Z0-9]|^)(rt|ht|cc|RT)([^a-zA-Z0-9]|$)', flags=re.UNICODE)\n",
    "\n",
    "def detweet(text):\n",
    "    return re.sub(url_pattern, '', \n",
    "               re.sub(rt_pattern, '', \n",
    "                      re.sub(mention_pattern2, '',\n",
    "                         re.sub(mention_pattern, '',\n",
    "                             re.sub(hashtag_pattern, '', \n",
    "                                 re.sub(emoji_pattern, '', \n",
    "                                    text))))))\n",
    "def normalize(text):\n",
    "    return re.sub(r\"\\s+\", \" \", #remove extra spaces\n",
    "                  re.sub(r'[^a-zA-Z0-9]', ' ', #remove non alphanumeric, incl punctuation\n",
    "                         text)).lower().strip() #lowercase and strip\n",
    "def fix_encoding_and_unescape(text):\n",
    "    return BeautifulSoup(text.decode('unicode-escape')).get_text()\n",
    "def preprocess(text, fix_encoding=False):\n",
    "    if (type(text)==str) or (type(text)==unicode):\n",
    "        if fix_encoding:\n",
    "            return normalize(detweet(fix_encoding_and_unescape(text)))\n",
    "        else:\n",
    "            return normalize(detweet(text))\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9332b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sexism_df['text_preprocessed'] = sexism_df['text'].apply(preprocess)\n",
    "adapt_data = tf.constant(sexism_df['text_preprocessed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a701ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = keras.layers.TextVectorization(output_mode=\"tf-idf\", ngrams=2)\n",
    "text_vectorizer.adapt(adapt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90cb247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 13:56:24.564973: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         9014016   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 128)         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 128)         114816    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 128)         114816    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,260,289\n",
      "Trainable params: 9,260,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('vectorizedNN.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a88ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(string_input)\n",
    "preds = model(x)\n",
    "end_to_end_model = keras.Model(string_input, preds)\n",
    "end_to_end_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "668127d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 70422)            1         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 1)                 9260289   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,260,290\n",
      "Trainable params: 9,260,289\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "end_to_end_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee75b4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 14:57:54.205899: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vectorizedNNe2e/assets\n"
     ]
    }
   ],
   "source": [
    "end_to_end_model.save('vectorizedNNe2e', save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
